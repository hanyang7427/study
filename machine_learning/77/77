二、线性回归
1.有监督学习的一般步骤
1)数据采集：读文件、爬虫抓取
2)数据清洗：过滤掉垃圾数据
3)数据预处理：标准化、范围缩放，等等
4)划分训练集和测试集：充分混淆，设定划分比例(8:2)
5)训练模型：根据训练集的数据寻找输入和输出之间的内在联系
6)验证模型：用测试集的数据检验模型的评价指标
7)保存模型：将模型对象保存到文件中
8)载入并应用模型进行数据预测、分类、聚类等等
2.线性回归的本质用一个指向方程y=kx+b方程，拟合样本数据
代码：linear.py、load.py
三、岭回归
通过为不用聚集度的训练样本分配不同的权重，尽可能削弱某些异常样本对回归结果的影响，提高模型的精度。
代码：ridge.py
四、多项式回归
用一个n次多项式曲线拟合训练样本，以改善对非线性数据的拟合精度。
代码：poly.py
多项式回归的次数并不是越高越好，因为它在考虑局部拟合精度的同时可以能会牺牲总体拟合精度，因此总和评价指标r2_score更加重要，因为它可以在很大程度上避免因为过度拟合造成的精度损失。
五、房屋价格分析
1.针对多种不同回归模型的选择
代码：house.py
2.比较不同特性对回归结果的影响差异
回归模型中提供了如下方法：
feature_importances_
代码：importance.py
六、共享单车需求分析
同样的回归模型，应用于不用粒度的样本集，可能会有不同的特性重要性排列，这是有回归器算法在特性选择上的差异性决定的。
代码：bike.py
七、简单分类器
通过对数的观察，人工发现数据类别的差异特征，进行分类。
代码：simple.py
八、逻辑分类器
逻辑分类器亦称线性分类器，主要适用于对服从线性边界的样本进行分类，惩罚系数越到分类边界的精确度越高，但速度可能会变慢。
代码：log.py
九、朴素贝叶斯分类器
对非线性边界的样本进行分类。
代码：nb.py
十、自动划分训练集和测试集
model_selection.train_test_split(
    总体输入, 总体输出, test_size=测试集比例, 随机度) ->
    (训练输入，测试输入，训练输出，测试输出)
十一、基于交叉验证的分类精度
model_selection.cross_val_score(model, x, y, cv=10,
    评价指标)
评价指标：
precision_weighted：精确度
recall_weighted: 召回率
f1_weighted: f1得分 = 2x精确度x召回率/(精确度+召回率)
accuracy: 精度=符合样本数/测试样本数
a, b
代数平均数：(a+b)/2
a-m=m-b->m=(a+b)/2
几何平均数：sqrt(ab)
mm=ab
m=sqrt(ab)
