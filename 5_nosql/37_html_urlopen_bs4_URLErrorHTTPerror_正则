html
www.runoob.com/html/

HTML:网页内容的载体
HyperText Markup Language  --> 标记
CSS:样式是表现
JS:实现特效


爬虫基础scraping
bs4模块(BeautifulSoup) 解析html
urllib.request

from urllib.request import urlopen
urlopen():打开一个给定URL字符串表示的web链接，并返回文件类型的对象
f = urlopen()
f.read()        # 读取所有字节

# 打开url得到html
from urllib.request import urlopen
html = urlopen('http://pythonscraping.com/pages/page1.html')
print(html.read())
print(html.read().decode('utf-8'))
# 生成BeautifulSoup对象，以后的提取都操作该对象
from bs4 import BeautifulSoup
from urllib.request import urlopen
html = urlopen('http://pythonscraping.com/pages/page1.html')
bs_obj = BeautifulSoup(html.read(),'lxml')

>>> type(bsobj)
<class 'bs4.BeautifulSoup'>

# 打印特定标签的内容
print(bsobj)
print(bsobj.html.body.h1)
print(bsobj.body.h1)
print(bsobj.html.h1)
注：bs4解析HTML标签是没有层级顺序的，以上几种都行，推荐第二种把各个层级都列出来

访问url 的错误处理
HTTP错误 或 URL错误
###################################################
# 捕获错误 demo
from urllib.request import urlopen
from urllib.error import HTTPError
from urllib.error import URLError
from bs4 import BeautifulSoup
def get_title(url):
    '''
    HTTPError:请求已经到达web服务器，http状态码是web服务器返回的v
            HTTP状态码，404,500...
    URLERROR:请求没有到达服务器
            三种可能：
                1)无网络连接
                2)连接不到特定服务器
                3)服务器不存在
    '''
    try:
        html = urlopen(url)
    except HTTPError as e:
        print(e)
        return None
    try:
        html = urlopen(url)
    except URLError as e:
        print(e)
        return None
    try:
        bsobj = BeautifulSoup(html.read(),'lxml')
        title = bsobj.body.h1
        return title
    except AttributeError:
        '''
        AttributeError:属性错误，试图获得一个HTML标签，但是该标签不存在，BS4返回一个空对象，并且抛出AttributeError异常
        '''
        return None
title = get_title('http://pythonscraping.com/pages/page1.html')
if title == None:
    print('Title not found')
else:
    print(title)

***** BeautifulSoup生成的对象拥有的一些属性
>>> from bs4 import BeautifulSoup
>>> bsobj = BeautifulSoup('<b id="tags" class="boldest">Extremely bold</b>' , 'lxml')
>>> bsobj
<html><body><b class="boldest" id="tags">Extremely bold</b></body></html>
>>> bsobj.name
'[document]'
>>> bsobj.contents
[<html><body><b class="boldest" id="tags">Extremely bold</b></body></html>]
>>> bsobj.contents[0].name
'html'
>>> bsobj.body
<body><b class="boldest" id="tags">Extremely bold</b></body>
>>> bsobj.body.contents
[<b class="boldest" id="tags">Extremely bold</b>]
>>> bsobj.b
<b class="boldest" id="tags">Extremely bold</b>
>>> bsobj.b.contents
['Extremely bold']
>>> bsobj.string
string
 |      Convenience property to get the single string within this tag.
 |
 |      :Return: If this tag has a single string child, return value
 |       is that string. If this tag has no children, or more than one
 |       child, return value is None. If this tag has one child tag,
 |       return value is the 'string' attribute of the child tag,
 |       recursively.

***** BeautifulSoup生成的对象拥有的一些方法
from bs4 import BeautifulSoup
bsobj = BeautifulSoup('<b id="tag1" class="boldest">Extremely bold</b>' , 'lxml')
bsobj.find('b')
bsobj.find('b',id='tag1')
# 关键字传参和字典传参
bsobj.find(id='tag1')
bsobj.find('',{'id':'tag1'})
bsobj.get_text()        # 获得tag内的text
bsobj.body.table.prettify()     # 人性化显示

# 每个标签都有自己的name和attrs
>>> bsobj.b.name
'b'
>>> bsobj.b.attrs
{'id': 'tag1', 'class': ['boldest']}
>>> bsobj.b['class']
['boldest']
>>> bsobj.b.attrs['id']
'tag1'

find()和fandAll()
find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)
 |      Return only the first child of this Tag matching the given
 |      criteria(条件).
findAll = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)
 |      Extracts a list of Tag objects that match the given
 |      criteria.  You can specify the name of the Tag and any
 |      attributes you want the Tag to have.
 |
 |      The value of a key-value pair in the 'attrs' map can be a
 |      string, a list of strings, a regular expression object, or a
 |      callable that takes a string and returns whether or not the
 |      string matches for some custom definition of 'matches'. The
 |      same is true of the tag name.

name:HTML标签，在<>里面
attrs:属性，比如<d id='tag2'>xxx</b>中的id
recursive：递归，是一个布尔型，True表示findAll函数还会搜索子节点，以及子节点的子节点

# 例
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')

bsobj = BeautifulSoup(html.read(),'lxml')
nameList = bsobj.findAll('span',{'class':'red'},text='the Prince')
print(len(nameList))
# 查找tr中的td或者th('td','th'放在列表里)
nameList = bsobj.find('tr').find(['td','th'])


正则表达式regular expression
1.如何通过编程使计算机具有在文本中检索某种模式的能力
2.为高级的文本模式匹配，抽取，或文本形式的搜索和替换功能提供基础
3.是一些有字符和特殊符号组成的字符串，它们描述了模式的重复或表述多个字符，于是正则表达式能按照某种模式匹配一系列有相似特征的字符串

常用正则表达式
匹配单个
.                 1个字符
\b                单词边界boundary
\B                非单词边界
\d                1个数字
\w                1个数字字母或下划线,等价于[a-zA-Z0-9_]
\s                空白字符
匹配前面的字符n次(注：前边必须有字符)
*                 匹配前边字符0+次
+                 匹配前边字符1+次
?                 匹配前边的字符0或1次
{n}               匹配前边字符n次
{n,m}             匹配前边字符n~m次
进阶
[0-9a-zA-Z_]            匹配一个数字，字母或下划线
[0-9a-zA-Z_]+           匹配至少由一个数字，字母或者下划线组成的字符串
[0-9a-zA-Z_]*           匹配由字母，数字下划线开头，后接任意个由一个数字，字母或下划线组成的字符串，也就是python的合法变量
[0-9a-zA-Z_]{0,19}      更精确地限制了变量的长度是1-20个字符(前面一个字符，后面最多19个字符)
[\s\S]*?                任意个任意字符包括换行

A|B             匹配A或B (p|P)可以匹配'python'或'Python'
^               行首 ^\d以数字开头
$               行尾 \d$以数字结尾

\d{3}\-\d{3,8}    010-1234567

import re
re.match()
re.search()
re.compile()
match(pattern, string, flags=0)
        Try to apply the pattern at the start of the string, returning
        a match object, or None if no match was found.
search(pattern, string, flags=0)
        Scan through string looking for a match to the pattern, returning
        a match object, or None if no match was found.
compile(pattern, flags=0)
        Compile a regular expression pattern, returning a pattern object.

以下来自www.liaoxuefeng.com
———————————————— 分组 group 提取子串 ————————————————
除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能，用()表示的就是要提取的分组(Group)
# 定义两个组，可以直接从匹配的字符串中提取出区号和本地号码
>>> m = re.match(r'^(\d{3})-(\d{3,8})$','010-12345')
>>> m
<_sre.SRE_Match object; span=(0, 9), match='010-12345'>     # match 对象
>>> m.group()
'010-12345'
>>> m.group(1)
'010'
>>> m.group(2)
'12345'
注：由于python的字符串本身也用\转义，使用r''代表不转义
———————————————— 命名分组 ————————————————
>>> m = re.match(r'^(\d{3})-(?P<name>\d{3,8})$','010-12345')
>>> m.group('name')
'12345'
>>> m.group(1)
'010'
>>> m.group(2)
'12345'
在括号内部的开始位置加 -> ?P<name>
例 ( ?P<name>\d{3,8} )
———————————————— 贪婪匹配 ————————————————
这则匹配默认是贪婪匹配，也就是匹配尽可能多的字符
# \d+是贪婪匹配直接把后面的0全部匹配了，结果0*只能匹配空字符串了
>>> re.match(r'^(\d+)(0*)$','102300').groups()
('102300', '')
# 必须让\d+采用非贪婪匹配(也就是尽可能的少匹配)，才能把后面的0匹配出来，加上个?就可以让d+采用非贪婪匹配
>>> re.match(r'^(\d+?)(0*)$','102300').groups()
('1023', '00')
一般使用懒惰模式

另一个例子
>>> re.search(r'[\s\S]*?@','adfda@@@')
<_sre.SRE_Match object; span=(0, 6), match='adfda@'>
>>> re.search(r'[\s\S]*@','adfda@@@')
<_sre.SRE_Match object; span=(0, 8), match='adfda@@@'>
—————————————————— 切分字符串 ————————————————
# 正常的split切分字符串，无法识别连续空格
>>> 'a b  c'.split(' ')
['a', 'b', '', 'c']
# re.split (\s+ 代表一个或过个空格)
>>> re.split(r'\s+','a b  c')
['a', 'b', 'c']
—————————————————— 编译 ————————————————
当我门在Python中使用正则表达式时，re模块内部会干两件事情：
1.编译正则表达式，如果正则表达式的字符串本身不合法，会报错
2.用编译后的正则表达式取匹配字符串
如果一个正则表达式要重复使用几千次，出于效率考虑，我们可以预编译该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配
# 编译
re_telephone = re.compile(r'(\d{3})-(\d{3,8})$')
# 使用
>>> re_telephone.match('010-12345').groups()
('010', '12345')
—————————————————— 替换 ————————————————
>>> re.sub('a','b','abcabc')
bbcbbc